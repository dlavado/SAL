
# Description: config file for default parameters of scenenet_ts40k experiment
# Author: Diogo Mateus

program: opt_main.py
method: random
metric:
  goal: maximize
  name: val_MulticlassAccuracy 
project: 'ADMM_AUGLAG_CIFAR10'
variables:
  - &dataset 'cifar10'
  - &model 'resnet'
command:
  #- ${env}
  - python3
  - ${program}
  - --wandb_sweep 
  - --model
  - *model
  - --dataset
  - *dataset
  #- ${args}
parameters:
  output_dir: 
    value: 'experiments/*model_*dataset/outputs'
  # ------------------ #
  # dataset config
  # ------------------ #
  dataset:
    value: *dataset
  data_path:
    value: ../datasets/cifar10/
  batch_size:
    value: 512
  num_workers:
    value: 12
  num_classes:
    value: 10
  # ------------------ #
  # model config
  # ------------------ #
  model:
    value: *model
  in_channels:
    value: 3
  pretrained:
    value: True
  # ------------------ #
  # training config
  # ------------------ #
  optimizer:
    value: 'adam' #'sgd' 
  learning_rate:
    min: 0.001
    max: 0.1
  max_epochs:
    value: 50 # -1 for infinite
  accelerator:
    value: 'gpu'
  devices:
    value: -1 # -1 for all available gpus
  early_stop_metric:
    value: 'val_loss'
  # ------------------ #
  # Checkpoint config
  # ------------------ #
  resume_from_checkpoint:
    value: False
  checkpoint_dir:
    value:  'experiments/resnet_cifar10/checkpoints'
  resume_checkpoint_name:
    value: val_MulticlassAccuracy
  checkpoint_every_n_epochs: # This parameter and the next one are mutually exclusive
    value: 1 # every n epochs
  checkpoint_every_n_steps:
    value: 0 # every n steps

  # ------------------ #
  # Lit Trainer config
  # ------------------ #
  fast_dev_run:
    value: True
  precision: # 16 or 32 FPU precision
    value: 16
    # description: 'FPU precision'
  auto_lr_find:
    value: False
  auto_scale_batch_size:
    value: False
  profiler:
    value: False
    # description: 'PyTorch Lightning profiler'
  accumulate_grad_batches:
    value: None
    # description: 'Accumulate gradients on k batches before performing a backward pass'
  save_onnx:
    value: False
    # description: 'Save model in onnx format'


  # ------------------ #
  # Opt Config
  # ------------------ #
  convergence_mode:
    values: ['penalty', 'admm', 'auglag'] # 'admm' or 'penalty' or 'auglag'
    #description: 'Convergence mode of the ADMM algorithm'
  admm_rho:
    min: 0.1
    max: 1.0
    #description: 'Initial value of the penalty parameter of the augmented Lagrangian method'
  admm_rho_update_factor:
    value: 1.0
    #description: 'Factor by which the penalty parameter is updated'
  admm_stepsize:
    value: 1.0
    # description: 'Step size of the ADMM algorithm'
  admm_stepsize_update_factor:
    value: 1.0
    # description: 'Factor by which the step size is updated'
  admm_rho_max:
    value: 10
    # description: 'Maximum value of the penalty parameter'
  convergence_iterations:
    value: 5
    # description: 'Number of iterations of the Augmented Lagrangian method to reach convergence'
  # ------------------ #
  # Constraint Config
  # ------------------ #
  ortho_weight:
    min: 0.001
    max: 0.1
    #description: 'Orthogonality constraint weight'
  sparse_weight:
    min: 0.001
    max: 0.1
    #description: 'L1 constraint weight'
    